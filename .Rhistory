cor(model1)
cor(training)
cor(training)
cor(training)
model2 <- lm(Temp ~ MEI + TSI + Aerosols + N2O, data = training)
summary(model2)
moneyball <- subset(baseball, Year < 2002)
moneyball$RD <- moneyball$RS - moneyball$RA
plot(moneyball$RD, moneyball$W)
plot(moneyball$RD, moneyball$W)
RunsReg <- lm(RS ~ OBP + SLG, data=moneyball)
summary(RunsReg)
View(moneyball)
View(moneyball)
newdata[, c("OBP", "SLG")] <- c(0.311, 0.405)
newdata
predict(RunsReg, newdata = newdata)
RunsAllowed <- lm(RA ~ OOBP + OSLG, data = moneyball)
summary(RunsAllowed)
newdata[, c("OOBP", "OSLG")] <- c(0.297, 0.370)
predict(RunsAllowed, newdata = newdata)
jugadores <- baseball[1:5,]
jugadores[1,c("OBP", "SLG")] <- c(0.338, 0.540)
jugadores[1,c("OBP", "SLG")] <- c(0.338, 0.540)
jugadores[2,c("OBP", "SLG")] <- c(0.391, 0.450)
jugadores[3,c("OBP", "SLG")] <- c(0.369, 0.450)
jugadores[4,c("OBP", "SLG")] <- c(0.313, 0.447)
jugadores[5,c("OBP", "SLG")] <- c(0.361, 0.500)
jugadores
jugadores[3,c("OBP", "SLG")] <- c(0.369, 0.374)
jugadores
predict(RunsReg, newdata = jugadores)
teamRank = c(1,2,3,3,4,4,4,4,5,5)
wins2012 <- c(94, 88, 95, 88, 93, 94, 98, 97, 93, 95)
wins2013 <- c(97, 97, 92, 93, 92, 96, 94, 96, 92, 90)
cor(teamRank, wins2012)
cor(teamRank, wins2013)
wins2012 <- c(94, 88, 95, 88, 93, 94, 98, 97, 93, 94)
cor(teamRank, wins2012)
minimodel <- step(model1)
summary(minimodel)
predict(minimodel, newdata = test)
testpredict <- predict(minimodel, newdata = test)
testpredict
testpredict
str(testpredict)
SSE = sum((training$Temp - testpredict)^2)
testpredict
SSE = sum((test$Temp - testpredict)^2)
SSE
SST = sum((test$Temp - mean(training$Temp))^2)
SST
SST
1 - (SSE/SST)
pisatrain <- read.csv("C:/EMC/Cursos/Analytics Edge/pisa2009train.csv")
View(pisatrain)
pisatest <- read.csv("C:/EMC/Cursos/Analytics Edge/pisa2009test.csv")
View(pisatest)
nrow(pisatrain)
tapply(pisatrain$readingScore, pisatrain$male)
tapply(pisatrain$readingScore, pisatrain$male , mean)
is.na(pisatrain)
View(pisatrain)
View(pisatrain)
for(i in 1:24){
pisatrain[,i]
}
for(i in 1:24){
is.na(pisatrain[,i])
}
print(is.na(pisatrain[,i]))
for(i in 1:24){
print(is.na(pisatrain[,i]))
}
print(mean(is.na(pisatrain[,i]))
}
for(i in 1:24){
print(mean(is.na(pisatrain[,i]))
}
for(i in 1:24){
print(mean(is.na(pisatrain[,i])))
}
names(pisatrain)
names(pisatrain)[1]
print(names(pisatrain)[i],mean(is.na(pisatrain[,i])))
for(i in 1:24){
print(names(pisatrain)[i],mean(is.na(pisatrain[,i])))
}
for(i in 1:24){
print(names(pisatrain)[i]), print(mean(is.na(pisatrain[,i])))
}
for(i in 1:24){
print(names(pisatrain)[i]) ; print(mean(is.na(pisatrain[,i])))
}
for(i in 1:24){
print(names(pisatrain)[i]) + print(mean(is.na(pisatrain[,i])))
}
for(i in 1:24){
cat(names(pisatrain)[i])
cat(mean(is.na(pisatrain[,i])))
}
for(i in 1:24){
cat(names(pisatrain)[i])
cat(mean(is.na(pisatrain[,i])))
print()
}
for(i in 1:24){
cat(names(pisatrain)[i])
cat(mean(is.na(pisatrain[,i])))
print("")
}
pisaTrain = na.omit(pisaTrain)
pisaTrain <- pisatrain
pisaTrain = na.omit(pisaTrain)
pisaTest <- pisatest
pisaTest = na.omit(pisaTest)
pisaTrain$raceeth = relevel(pisaTrain$raceeth, "White")
str(pisaTrain)
lmScore <- lm(readingScore ~ ., data = pisaTrain)
summary(lmScore)
sqrt(mean(lmScore$residuals^2))
summary(lmScore)$coef[2,1]*(11-9)
View(training)
prediction <- predict(readingScore, newdata = pisaTest)
prediction
View(pisaTest)
prediction <- predict(lmScore, newdata = pisaTest)
prediction
summary(prediction)
637.7 - 353.2
SSE <- sum((prediction - pisaTest$readingScore)^2)
SSE
RMSE = sqrt(SSE/nrow(pisaTest))
RMSE
baseline = mean(pisaTrain$readingScore)
baseline
SST = sum((baseline - pisaTest$readingScore)^2)
SST
1 - (SSE/SST)
FluTrain <- read.csv("C:/EMC/Cursos/Analytics Edge/FluTrain.csv")
View(FluTrain)
max(FluTrain$ILI)
which(max(FluTrain$ILI))
which(FluTrain$ILI = max(FluTrain$ILI))
which(FluTrain$ILI == max(FluTrain$ILI))
FluTrain[which(FluTrain$ILI == max(FluTrain$ILI)),]
FluTrain[which(FluTrain$Queries == max(FluTrain$Queries)),]
xlab = "", col = "blue")
hist(ILI, main = "Distribution of Influenza Like Illness related Physician Visits", xlab = "", col = "blue")
hist(FluTrain$ILI, main = "Distribution of Influenza Like Illness related Physician Visits", xlab = "", col = "blue")
plot(log(FluTrain$ILI), Queries)
plot(log(FluTrain$ILI), FluTrain$Queries)
FluTrend1 <- lm(log(ILI) ~ Queries, data = FluTrain)
summary(FluTrend1)
cor(log(FluTrain$ILI), FluTrain$Queries)
FluTest <- read.csv("C:/EMC/Cursos/Analytics Edge/FluTest.csv")
View(FluTest)
PredTest1 = exp(predict(FluTrend1, newdata=FluTest))
PredTest1[which(fluTest$Week == "2012-03-11 - 2012-03-17")]
PredTest1[which(FluTest$Week == "2012-03-11 - 2012-03-17")]
SSE = sum((PredTest1 - fluTest$ILI)^2)
FluTest[which(FluTest$Week == "2012-03-11 - 2012-03-17")]
FluTest[which(FluTest$Week == "2012-03-11 - 2012-03-17"),]
(2.29342 - 2.187378)/ 2.293422
install.packages("zoo")
library(zoo)
ILILag2 = lag(zoo(FluTrain$ILI), -2, na.pad=TRUE)
FluTrain$ILILag2 = coredata(ILILag2)
length(ILILag2) - length(na.omit(ILILag2))
plot(log(ILI), log(ILILag2), col = "blue")
plot(log(FluTrain$ILI), log(ILILag2), col = "blue")
FluTrend2 <- lm(log(ILI) ~ Queries + log(ILILag2), data = fluTrain)
summary(FluTrend2)
FluTrend2 <- lm(log(ILI) ~ Queries + log(ILILag2), data = FluTrain)
summary(FluTrend2)
RMSE = sqrt(SSE/nrow(FluTest))
RMSE
ILILag2 = lag(zoo(FluTest$ILI), -2, na.pad = TRUE)
FluTest$ILILag2 = coredata(ILILag2)
length(FluTest$ILILag2) - length(na.omit(FluTest$ILILag2))
fluTest$ILILag2[1] <- fluTrain$ILI[nrow(fluTrain) - 1]
fluTest$ILILag2[2] <- fluTrain$ILI[nrow(fluTrain)]
FluTest$ILILag2[1] <- FluTrain$ILI[nrow(FluTrain) - 1]
FluTest$ILILag2[2] <- FluTrain$ILI[nrow(FluTrain)]
FluTest$ILILag2[1]
FluTest$ILILag2[2]
PredTest2 = exp(predict(FluTrend2, newdata = FluTest))
# RMSE
sqrt(mean((PredTest2 - FluTest$ILI)^2))
qnorm(0.025)
qnorm(0.1)
gerber <- read.csv("C:/EMC/Cursos/Analytics Edge/gerber.csv")
View(gerber)
names(gerber)
table(gerber$voting)/nrow(gerber)
vote = read.csv("gerber.csv")
vote <- gerber
nrow(subset(vote, vote$voting == 1))/nrow(vote)
tapply(vote, voting, sum)
nrow(subset(vote, vote$civicduty == 1)) # Civic Duty
nrow(subset(vote, vote$hawthorne == 1)) # Hawthorne Effect
nrow(subset(vote, vote$self == 1)) # Self
nrow(subset(vote, vote$neighbors == 1)) # Neighbors
tapply(vote$voting, vote$civicduty, mean)
tapply(vote$voting, vote$hawthorne, mean)
tapply(vote$voting, vote$self, mean)
tapply(vote$voting, vote$neighbors, mean) # THIS
voteLog = glm(voting ~ civicduty + hawthorne + self + neighbors, data=vote, family=binomial)
summary(voteLog)
predictVote = predict(voteLog, type="response")
table(vote$voting, predictVote>=0.3)
m1 <- glm(voting ~ hawthorne + civicduty +
neighbors + self,
data = gerber, family = "binomial")
summary(m1)
pred <- predict(m1, type = "response")
str(pred)
table(gerber$voting, pred > 0.3)
t <- table(gerber$voting, pred > 0.3)
(t[1, 1] + t[2, 2]) / sum(t)
table(gerber$voting, pred > 0.5)
t <- table(gerber$voting, pred > 0.5)
t[1, 1] / sum(t)
library(ROCR)
ROCRpred = prediction(pred, gerber$voting)
as.numeric(performance(ROCRpred, "auc")@y.values)
library(rpart)
library(rpart.plot)
install.packages(rpart.plot)
library("rpart", lib.loc="C:/Program Files/R/R-3.1.2/library")
library(rpart.plot)
prp(CARTmodel)
CARTmodel = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber)
prp(CARTmodel)
install.packages("rpart.plot")
library(rpart.plot)
CARTmodel = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber)
prp(CARTmodel)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
CARTmodel2 = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber, cp=0.0)
install.packages("rpart.plot")
library(rpart.plot)
CARTmodel2 = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber, cp=0.0)
prp(CARTmodel2)
CARTmodel3 = rpart(voting ~ sex + civicduty + hawthorne + self + neighbors, data=gerber, cp=0.0)
prp(CARTmodel3)
CARTmodel4 = rpart(voting ~ control, data=gerber, cp=0.0)
CARTmodel5 = rpart(voting ~ control + sex, data=gerber, cp=0.0)
prp(CARTmodel4, digits = 6)
abs(0.296638 - 0.34)
prp(CARTmodel5, digits = 6)
m2 <- glm(voting ~ sex + control,
data = gerber, family = "binomial")
summary(m2)
Possibilities = data.frame(sex=c(0,0,1,1),control=c(0,1,0,1))
predict(LogModelSex, newdata=Possibilities, type="response")
Possibilities = data.frame(sex=c(0,0,1,1),control=c(0,1,0,1))
predict(m2, newdata=Possibilities, type="response")
prp(CARTmodel5, digits = 6)
abs(0.2908065 - 0.290456)
LogModel2 = glm(voting ~ sex + control + sex:control, data=gerber, family="binomial")
summary(LogModel2)
predict(LogModel2, newdata=Possibilities, type="response")
abs(0.2904558 - 0.290456)
letters <- read.csv("C:/EMC/Cursos/Analytics Edge/letters_ABPR.csv")
View(letters)
letters$isB = as.factor(letters$letter == "B")
library(caTools)
set.seed(1000)
split = sample.split(letter$isB, SplitRatio = 0.5)
letter <- letters
letters$isB = as.factor(letters$letter == "B")
library(caTools)
set.seed(1000)
split = sample.split(letter$isB, SplitRatio = 0.5)
Train = subset(letter, split==TRUE)
Test = subset(letter, split==FALSE)
summary(Train)
library(rpart)
library(rpart.plot)
CARTb = rpart(isB ~ . - letter, data=Train, method="class")
PredictCART = predict(CARTb, newdata = Test, type = "class")
table(Test$isB, PredictCART)
letter$letter = as.factor( letter$letter )
# Generating new data
set.seed(2000)
split = sample.split(letter$letter, SplitRatio = 0.5)
Train = subset(letter, split==TRUE)
Test = subset(letter, split==FALSE)
summary(Test)
0.2535302 + 0.2458280 + 0.2573813  + 0.2432606
census <- read.csv("C:/EMC/Cursos/Analytics Edge/census.csv")
View(census)
library(caTools)
set.seed(2000)
split = sample.split(census$over50k, SplitRatio = 0.6)
train = subset(census, split==TRUE)
test = subset(census, split==FALSE)
# Building logistic regression
censusLog = glm(over50k ~ ., data=train, family=binomial)
summary(censusLog)
library(UsingR)
data(father.son)
plot(father.son$fheight, father.son$sheight)
cor(father.son$fheight, father.son$sheight)
identify(father.son$fheight, father.son$sheight)
x = father.son$fheight
y = father.son$sheight
n = nrow(father.son)
plot(scale(x), scale(y))
abline(h=0, v=0)
sum(scale(x) * scale(y)) / (n - 1)
sum(scale(x) * scale(y))
sum(scale(x) * scale(y)) / n
data(nym.2002)
head(nym.2002)
histogram(nym.2002$time)
qqnorm(nym.2002$time)
tail(sort(table(nym.2002$home)),10)
time = sort(nym.2002$time)
summary(time)
max(time/median(time))
min(time/median(time))
babies = read.table("https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt", header=TRUE)
bwt.nonsmoke = babies$bwt[babies$smoke==0]
bwt.smoke = babies$bwt[babies$smoke==1]
# QUESTION 1.1
# What is the average length of the confidence interval?
N=30
conf.int<-function(){
sample.bwt.nonsmoke <- sample(bwt.nonsmoke,N)
sample.bwt.smoke <- sample(bwt.smoke,N)
bwt.test <- t.test(sample.bwt.nonsmoke,sample.bwt.smoke)
return (bwt.test$conf.int[2] - bwt.test$conf.int[1])
}
mean(replicate(1000, conf.int()))
# QUESTION 1.2
# How often (what proportion of times) did the confidence intervals contain the population-level difference?
popdiff = mean(bwt.nonsmoke) - mean(bwt.smoke)
N=30
diff.compare<-function(){
sample.bwt.nonsmoke <- sample(bwt.nonsmoke,N)
sample.bwt.smoke <- sample(bwt.smoke,N)
bwt.test <- t.test(sample.bwt.nonsmoke,sample.bwt.smoke)
return (popdiff>bwt.test$conf.int[1] & popdiff<bwt.test$conf.int[2])
}
mean(replicate(1000, diff.compare()))
# QUESTION 1.3
# the difference in means (X.ns - X.s) must have absolute value greater than _____ times sd.diff in order for the result to be significant (at alpha=0.05).
# QUESTION 1.4
# the difference in means (X.ns - X.s) must be a greater distance than _____ times sd.diff away from 0 in order for the 95% confidence interval not to contain 0.
# QUESTION 3.1
# What is the power at alpha=0.1?
N=15
reject <- function(N,alpha){
sample.bwt.nonsmoke <- sample(bwt.nonsmoke,N)
sample.bwt.smoke <- sample(bwt.smoke,N)
pval <- t.test(sample.bwt.nonsmoke,sample.bwt.smoke)$p.value
ifelse(pval < alpha,1,0)
}
mean(replicate(1000,reject(N,0.1)))
# QUESTION 3.2
# What is the power at alpha=0.05?
mean(replicate(1000,reject(N,0.05)))
# QUESTION 3.3
# QUESTION 3.3
# What is the power at alpha=0.01?
mean(replicate(1000,reject(N,0.01)))
# QUESTION 3.4
# What is the expected number of student responses that would be marked wrong simply by chance?
# QUESTION 2.1
# What is the X-squared statistic?
d = read.csv("https://courses.edx.org/c4x/HarvardX/PH525.1x/asset/assoctest.csv")
d = read.csv("https://courses.edx.org/c4x/HarvardX/PH525.1x/asset/assoctest.csv")
d.table <- table(d)
chisq.test(d.table)$statistic
# QUESTION 2.2
# What is the p-value?
fisher.test(d.table)$p.value
babies = read.table("https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt", header=TRUE)
bwt.nonsmoke = babies$bwt[babies$smoke==0]
bwt.smoke = babies$bwt[babies$smoke==1]
# QUESTION 1.1
# How often (what proportion of simulations) is the sample variance greater than 1.5 times the population variance?
pop.var = var(bwt.nonsmoke)
vars = replicate(1000, var(sample(bwt.nonsmoke,10)))
mean(vars > pop.var*1.5)
# QUESTION 1.2
# Now use a sample size of 50. How often (what proportion) is the sample variance larger than 1.5 times the population variance?
vars = replicate(1000, var(sample(bwt.nonsmoke,50)))
mean(vars > pop.var*1.5)
# QUESTION 2.1
# QUESTION 2.1
# What is the p-value for the two groups of 50 defined above?
set.seed(0)
N=50
smokers <- sample(babies$bwt[babies$smoke==1],N)
nonsmokers <- sample(babies$bwt[babies$smoke==0],N)
obs <- mean(smokers)-mean(nonsmokers)
avgdiff <- replicate(1000, {
all <- sample(c(smokers,nonsmokers))
smokersstar <- all[1:N]
nonsmokersstar <- all[(N+1):(2*N)]
return(mean(smokersstar) - mean(nonsmokersstar))
})
mean(abs(avgdiff) > abs(obs))
library("dplyr")
# QUESTION 1.1
# What is the median REM proportion of the order with the smallest median REM proportion?
msleep<-read.csv("https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/msleep_ggplot2.csv")
msleep %>%
mutate(rem_proportion = sleep_rem / sleep_total) %>%
group_by(order) %>%
summarise(median_rem_proportion = median(rem_proportion)) %>%
arrange(median_rem_proportion) %>%
head(1)
#======================================================================
# Week 4 Robust summaries
#======================================================================
data(ChickWeight)
chick = reshape(ChickWeight,idvar=c("Chick","Diet"),timevar="Time",direction="wide")
chick = na.omit(chick)
ChickWeight[ChickWeight$Chick==,]
data(ChickWeight)
chick = reshape(ChickWeight,idvar=c("Chick","Diet"),timevar="Time",direction="wide")
chick = na.omit(chick)
ChickWeight[ChickWeight$Chick==,]
data(ChickWeight)
plot(ChickWeight$Time, ChickWeight$weight, col=ChickWeight$Diet)
head(ChickWeight)
chick = reshape(ChickWeight,idvar=c("Chick","Diet"),timevar="Time",direction="wide")
head(chick)
chick = na.omit(chick)
mean(c(chick$weight.4,3000))/mean(chick$weight.4)
median(c(chick$weight.4,3000))/median(chick$weight.4)
sd(c(chick$weight.4,3000))/sd(chick$weight.4)
mad(c(chick$weight.4,3000))/mad(chick$weight.4)
mean(c(chick$weight.4, 3000))/mean(chick$weight.4)
median(c(chick$weight.4, 3000))/median(chick$weight.4)
sd(c(chick$weight.4, 3000))/sd(chick$weight.4)
cor(c(chick$weight.4,3000), c(chick$weight.21,3000)) / cor(chick$weight.4, chick$weight.21)
x<-subset(chick$weight.4,chick$Diet==1)
y<-subset(chick$weight.4,chick$Diet==4)
t.test(c(x,200),y)$p.value
data(ChickWeight)
plot(ChickWeight$Time, ChickWeight$weight, col=ChickWeight$Diet)
head(ChickWeight)
chick = reshape(ChickWeight,idvar=c("Chick","Diet"),timevar="Time",direction="wide")
head(chick)
chick = na.omit(chick)
mean(c(chick$weight.4,3000))/mean(chick$weight.4)
median(c(chick$weight.4,3000))/median(chick$weight.4)
sd(c(chick$weight.4,3000))/sd(chick$weight.4)
mad(c(chick$weight.4,3000))/mad(chick$weight.4)
plot(chick$weight.4~chick$weight.21)
cor(c(chick$weight.4,3000),c(chick$weight.21,3000))/cor(chick$weight.4,chick$weight.21)
cor(c(chick$weight.4,3000),c(chick$weight.21,3000), method = 'spearman')/cor(chick$weight.4,chick$weight.21,method = 'spearman')
t.test(x,y+10)$statistic-t.test(x,y+100)$statistic
x<-subset(chick$weight.4,chick$Diet==1)
y<-subset(chick$weight.4,chick$Diet==4)
t.test(c(x,200),y)$p.value
# QUESTION 2.2
# What is the difference in t-test statistic (the statistic is obtained by t.test(x,y)$statistic) between adding 10 and adding 100 to all the values in the group 'y'?
t.test(x,y+10)$statistic-t.test(x,y+100)$statistic
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(swirl)
install_from_swirl("Exploratory Data Analysis")
switrl()
swirl()
setwd("c:/emc/cursos/Github/Practice-With-Titanic")
train <- read.csv("train.csv")
test <- read.csv("test.csv")
setwd("c:/emc/cursos/Github/Practice-With-Titanic")
train <- read.csv("train.csv")
test <- read.csv("test.csv")
train <- read.csv("train.csv")
train <- read.csv("train.csv")
getwd()
train <- read.csv("train.csv")
train <- read.csv("train.csv")
test <- read.csv("test.csv")
train <- read.csv("train.csv")
test <- read.csv("test.csv")
library(rpart)
library(rpart.plot)
library(caTools)
library(ROCR)
library(caret)
library(e1071)
library(randomForest)
library(flexclust)
```
Formating the Data
```{r}
train$Survived <- as.factor(train$Survived)
train$Pclass <- as.factor(train$Pclass)
train$Embarked <- as.character(train$Embarked)
#train$Title <- as.factor(train$Title)
test$Pclass <- as.factor(test$Pclass)
test$Embarked <- as.character(test$Embarked)
#test$Title <- as.factor(test$Title)
```
train <- read.csv("train.csv")
test <- read.csv("test.csv")
View(train)
